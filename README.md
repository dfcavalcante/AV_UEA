# ü§ñ Assistente Virtual UEA - RAG Local

## üìÑ Resumo sobre o projeto
Este projeto implementa um sistema de **RAG (Retrieval-Augmented Generation)** projetado para responder perguntas sobre documentos institucionais da **Universidade do Estado do Amazonas (UEA)**, especificamente o Estatuto e o Regimento das Casas do Estudante.

O diferencial deste projeto √© sua capacidade de operar **100% localmente em CPU**, utilizando modelos de linguagem eficientes (Qwen-0.5B) e orquestra√ß√£o via Docker, reprodutibilidade e baixo consumo de recursos.

---

## üèóÔ∏è Arquitetura Geral
O sistema segue uma arquitetura modular desacoplada em tr√™s camadas principais:

1.  **Camada de Ingest√£o (`src/ingest.py`):**
    * Respons√°vel por ler os arquivos PDF da pasta `data/pdfs/`.
    * Utiliza **PyMuPDF** para extra√ß√£o limpa de texto.
    * Aplica t√©cnica de *Chunking* (tamanho 1000, overlap 200) para preservar o contexto de artigos de lei.
    * Gera vetores (embeddings) e os armazena em um √≠ndice **FAISS**.

2.  **Camada RAG Core (`src/rag.py`):**
    * Atua como o motor de intelig√™ncia.
    * Realiza a busca vetorial para recuperar os trechos mais relevantes.
    * Implementa um **Re-ranking H√≠brido** (detalhado nas funcionalidades adicionais) para refinar os resultados antes de envi√°-los ao LLM.
    * Utiliza o modelo **Qwen/Qwen2.5-0.5B-Instruct** para gerar a resposta final em linguagem natural.

3.  **Camada de Interface (`api/main.py`):**
    * Servidor **FastAPI** que exp√µe as funcionalidades via HTTP.
    * Gerencia o ciclo de vida dos modelos, carregando-os apenas uma vez na inicializa√ß√£o.

---

## üöÄ Como rodar o projeto
O projeto utiliza **Docker Compose** para orquestra√ß√£o. N√£o √© necess√°rio instalar Python ou bibliotecas localmente, apenas o Docker.

1.  **Clone o reposit√≥rio e entre na pasta:**
    ```bash
    git clone https://github.com/dfcavalcante/AV_UEA.git
    cd AV_UEA
    ```

2.  **Execute o comando de inicializa√ß√£o:**
    Este comando ir√° construir a imagem, baixar os modelos de IA e iniciar o servi√ßo.
    ```bash
    docker-compose up --build
    ```
    *(Aguarde at√© aparecer a mensagem "‚úÖ Servidor Online!" no terminal).*
    
    ** E acesse:**
    http://localhost:8000/docs

## üêç Execu√ß√£o Manual (Sem Docker - Opcional)
Caso prefira rodar o projeto diretamente em seu ambiente Python local (Windows/Linux/Mac).

**Pr√©-requisitos:** Python 3.10 ou superior.

1.  **Crie e ative um ambiente virtual:**
    ```bash
    # Windows
    python -m venv venv
    .\venv\Scripts\activate

    # Linux/Mac
    python3 -m venv venv
    source venv/bin/activate
    ```

2.  **Instale as depend√™ncias:**
    O `requirements.txt` j√° est√° otimizado para baixar a vers√£o leve (CPU) do PyTorch.
    ```bash
    pip install -r requirements.txt
    ```

3.  **Realize a Ingest√£o dos Documentos:**
    Como n√£o est√° usando o script autom√°tico do Docker, voc√™ deve criar o banco vetorial manualmente na primeira vez.
    ```bash
    python src/ingest.py
    ```

4.  **Inicie a API:**
    ```bash
    uvicorn api.main:app --host localhost --port 8000 --reload
    ```

5.  **Acesse:**
    http://localhost:8000/docs

---

## üîÑ Como regenerar o √≠ndice
O banco de dados vetorial (FAISS) √© salvo em um volume do Docker para evitar reprocessamento desnecess√°rio. Caso voc√™ adicione novos PDFs ou altere as configura√ß√µes de chunking, √© necess√°rio for√ßar a recria√ß√£o do √≠ndice:

1.  Pare o servi√ßo e **remova os volumes** (isso apaga o banco atual):
    ```bash
    docker-compose down -v
    ```
2.  Suba a aplica√ß√£o novamente:
    ```bash
    docker-compose up --build
    ```
    *O sistema detectar√° automaticamente que o √≠ndice n√£o existe e executar√° o script de ingest√£o antes de iniciar a API.*

### Via Execu√ß√£o Manual (Sem Docker)
Se voc√™ estiver rodando o projeto diretamente no Python localmente:

1.  **Apague a pasta do banco antigo:**
    Delete manualmente a pasta `data/vectorstore` (ou os arquivos `index.faiss` e `chunks.pkl` dentro dela).
    * **Windows (PowerShell):** `Remove-Item -Recurse -Force data/vectorstore`
    * **Linux/Mac:** `rm -rf data/vectorstore`

2.  **Rode o script de ingest√£o:**
    ```bash
    python src/ingest.py
    ```

---

## üîå Como chamar a API

1.  Com o projeto rodando, acesse **http://localhost:8000/docs** no seu navegador.
2.  Localize a rota **`POST /ask`** e clique nela.
3.  Clique no bot√£o **"Try it out"**.
4.  No campo **Request body**, envie sua pergunta no formato JSON:
    ```json
    {
      "question": "Segundo o Estatuto, como √© constitu√≠do o patrim√¥nio da Universidade?"
    }
    ```
5.  Clique em **"Execute"** e veja a resposta no campo **Response body**.

---

## ‚úÖ Funcionalidades obrigat√≥rias implementadas
O projeto atende a 100% dos requisitos solicitados no desafio:

1.  **Pipeline de Ingest√£o de Documentos:** Leitura de PDFs, chunking e indexa√ß√£o vetorial autom√°tica.
2.  **Execu√ß√£o de Modelo LLM Local:** Integra√ß√£o com modelo *Open Source* rodando localmente.
3.  **Otimiza√ß√£o para CPU:** Configura√ß√£o expl√≠cita de `torch --index-url .../cpu` e uso de modelos leves para execu√ß√£o sem GPU.
4.  **Pipeline de RAG:** Implementa√ß√£o completa do fluxo de Recupera√ß√£o (Retrieval) e Gera√ß√£o (Generation).
5.  **API HTTP:** Cria√ß√£o de endpoint REST via FastAPI.
6.  **Dockeriza√ß√£o:** Cria√ß√£o de `Dockerfile` e `docker-compose.yml` funcionais.

---

## ‚ú® Funcionalidades adicionais implementadas
Para garantir maior qualidade e robustez, foram implementadas as seguintes funcionalidades extras:

1.  **Busca H√≠brida com Re-ranking:**
    * Al√©m da busca vetorial simples, o sistema aplica um algoritmo de reclassifica√ß√£o. Ele pontua mais alto trechos que cont√™m palavras-chave exatas da pergunta e prioriza a fonte correta (ex: se a pergunta menciona "Estatuto", documentos com "Estatuto" no nome ganham prioridade), reduzindo alucina√ß√µes.

2.  **Orquestra√ß√£o Inteligente (`start.sh`):**
    * Script shell personalizado que gerencia a l√≥gica de inicializa√ß√£o. Ele verifica a exist√™ncia do banco vetorial e decide automaticamente se deve rodar a ingest√£o ou iniciar a API diretamente, economizando tempo.

3.  **Tratamento de Compatibilidade (Windows/Linux):**
    * Configura√ß√£o de `.dockerignore` e tratamento de quebras de linha (LF/CRLF) no Dockerfile para garantir que o projeto rode em qualquer sistema operacional sem erros de script.

4.  **Endpoint de Health Check (`GET /health`):**
    * Implementa√ß√£o de uma rota de monitoramento que retorna o status da aplica√ß√£o.

## ‚ö†Ô∏è Observa√ß√µes T√©cnicas e Limita√ß√µes

### Comportamento do Modelo (Small Language Model)
Este projeto utiliza o modelo **Qwen-0.5B**, uma vers√£o extremamente leve projetada para rodar em CPUs modestas. Devido ao tamanho reduzido de par√¢metros:
1.  **Alucina√ß√µes de Conhecimento Externo:** Embora o *prompt* instrua o modelo a responder apenas sobre o contexto, modelos dessa escala (0.5B) podem ocasionalmente priorizar seu conhecimento pr√©vio de treinamento em perguntas de conhecimento geral.
2.  **Decis√£o de Design:** Optou-se por **n√£o implementar filtros r√≠gidos** para a identifica√ß√£o de perguntas desconexas ao contexto fornecido. Testes mostraram que filtros r√≠gidos tendem a gerar **Falsos Negativos**, bloqueando perguntas v√°lidas sobre a universidade que utilizam termos comuns.
